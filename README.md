# Parquet2MBT

ä¸€ä¸ªé«˜æ€§èƒ½çš„Parquetåˆ°MegatronäºŒè¿›åˆ¶æ ¼å¼ (Megatron Binary Type, MBT) è½¬æ¢å·¥å…·ï¼Œä¸“ä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é¢„å¤„ç†è€Œè®¾è®¡ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½**: å¤šçº¿ç¨‹æµæ°´çº¿æ¶æ„ï¼Œå……åˆ†åˆ©ç”¨CPUå’ŒI/Oèµ„æº
- ğŸ“Š **æ‰¹é‡å¤„ç†**: æ”¯æŒé€’å½’ç›®å½•æ‰«æï¼Œæ‰¹é‡è½¬æ¢Parquetæ–‡ä»¶
- ğŸ”§ **çµæ´»é…ç½®**: æ”¯æŒå¤šåˆ—æ–‡æœ¬æ‹¼æ¥ã€è‡ªå®šä¹‰åˆ†è¯å™¨ã€å¯é…ç½®è¾“å‡ºæ ¼å¼
- ğŸ“ˆ **å®æ—¶ç›‘æ§**: å†…ç½®æŒ‡æ ‡ç›‘æ§ï¼Œå®æ—¶æ˜¾ç¤ºè½¬æ¢è¿›åº¦å’Œæ€§èƒ½ç»Ÿè®¡
- ğŸ›¡ï¸ **å¯é æ€§**: æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€åŸå­å†™å…¥ã€é”™è¯¯æ¢å¤
- ğŸ¯ **å…¼å®¹æ€§**: è¾“å‡ºæ ¼å¼å®Œå…¨å…¼å®¹Megatron-LMçš„IndexedDataset

## æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- **ç¡¬ä»¶**: 128æ ¸CPU + 8Ã—RTX4090 GPU + é«˜é€ŸSSD
- **æ•°æ®é›†**: zh__CCI4.0-M2-Base-v1 (250ä¸ªParquetæ–‡ä»¶)
- **åˆ†è¯å™¨**: æ ‡å‡†ä¸­æ–‡åˆ†è¯å™¨ (~100Kè¯æ±‡è¡¨)

### æ€§èƒ½è¡¨ç°
- **å³°å€¼æ€§èƒ½**: **151.6M tokens/s** (ç¨³å®šçŠ¶æ€)
- **æœ€ä¼˜é…ç½®**: 5è¯»å– + 120åˆ†è¯ + 3å†™å…¥ workers (åœ¨128æ ¸CPU, batch-size=2048ç¯å¢ƒä¸‹)
- **I/Oååé‡**: 411.9 MB/s è¾“å…¥, 578.2 MB/s è¾“å‡º (å³°å€¼æ€§èƒ½åŒºé—´)

### æ—¶é—´ä¼°ç®—

| æ•°æ®è§„æ¨¡ | Tokenæ•°é‡ | é¢„ä¼°è½¬æ¢æ—¶é—´ | è¯´æ˜ |
|----------|-----------|-------------|------|
| å°è§„æ¨¡   | 1B tokens | ~6.4ç§’      | å•æœ¬å°è¯´/æ–‡æ¡£é›† |
| ä¸­è§„æ¨¡   | 10B tokens | ~1.1åˆ†é’Ÿ    | ä¸­å‹è¯­æ–™åº“ |
| å¤§è§„æ¨¡   | 100B tokens | ~10.8åˆ†é’Ÿ   | å¤§å‹é¢„è®­ç»ƒæ•°æ®é›† |
| è¶…å¤§è§„æ¨¡ | 1T tokens | ~1.8å°æ—¶    | è¶…å¤§è§„æ¨¡è¯­æ–™åº“ |

**æ³¨æ„**: å®é™…è½¬æ¢æ—¶é—´å—ä»¥ä¸‹å› ç´ å½±å“ï¼š
- ç¡¬ä»¶é…ç½®ï¼ˆCPUæ ¸æ•°ã€å†…å­˜å¸¦å®½ã€å­˜å‚¨é€Ÿåº¦ï¼‰
- æ•°æ®ç‰¹å¾ï¼ˆæ–‡æœ¬é•¿åº¦ã€å‹ç¼©æ¯”ã€æ–‡ä»¶æ•°é‡ï¼‰
- åˆ†è¯å™¨å¤æ‚åº¦ï¼ˆè¯æ±‡è¡¨å¤§å°ã€ç®—æ³•ç±»å‹ï¼‰
- ç³»ç»Ÿè´Ÿè½½ï¼ˆå…¶ä»–è¿›ç¨‹å ç”¨ã€I/Oç«äº‰ï¼‰

### ğŸ¤– æ™ºèƒ½Workeråˆ†é…

**æ— éœ€æ‰‹åŠ¨é…ç½®ï¼** ç³»ç»Ÿä¼šæ ¹æ®CPUæ ¸å¿ƒæ•°è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„workeråˆ†é…ç­–ç•¥ï¼š

```bash
# ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°å¹¶åº”ç”¨æœ€ä¼˜é…ç½®
./target/release/parquet2mbt \
  --input-dir /data/corpus \
  --tokenizer /models/tokenizer.json \
  --output-prefix /output/corpus
```

**åˆ†å±‚è‡ªé€‚åº”åˆ†é…ç­–ç•¥**ï¼ˆåŸºäºæ€§èƒ½æµ‹è¯•æ•°æ®ï¼‰:
- **0-32æ ¸**: 2è¯»å– + 1å†™å…¥ + å‰©ä½™åˆ†è¯
- **33-64æ ¸**: 3è¯»å– + 1å†™å…¥ + å‰©ä½™åˆ†è¯
- **65-96æ ¸**: 4è¯»å– + 2å†™å…¥ + å‰©ä½™åˆ†è¯
- **97-160æ ¸**: 6è¯»å– + 2å†™å…¥ + å‰©ä½™åˆ†è¯
- **160+æ ¸**: æŒ‰æ¯”ä¾‹åˆ†é…ï¼ˆè¯»/å†™workeræœ‰ä¸Šé™ï¼Œé¿å…è¿‡åº¦åˆ†é…ï¼‰

**é«˜çº§ç”¨æˆ·** ä»å¯æ‰‹åŠ¨æŒ‡å®šworkeræ•°é‡æ¥è¦†ç›–è‡ªåŠ¨é…ç½®ï¼š
```bash
# æ‰‹åŠ¨æŒ‡å®šï¼ˆä»…åœ¨ç‰¹æ®Šéœ€æ±‚æ—¶ä½¿ç”¨ï¼‰
./target/release/parquet2mbt \
  --input-dir /data/corpus \
  --tokenizer /models/tokenizer.json \
  --output-prefix /output/corpus \
  --read-workers 4 \
  --tokenize-workers 122 \
  --write-workers 2
```

## å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èä½¿ç”¨Dockerï¼‰

### 1. æ„å»ºDockeré•œåƒ
```bash
docker build -t parquet2mbt:latest -f deploy/docker/Dockerfile .
```
> **æç¤º**: å¦‚é‡æƒé™é—®é¢˜ï¼Œè¯·å…ˆå°†å½“å‰ç”¨æˆ·åŠ å…¥ `docker` ç»„ã€‚

### 2. è¿è¡Œè½¬æ¢ä»»åŠ¡
```bash
# å‡†å¤‡æœ¬åœ°ç›®å½•
DATA_DIR=/path/to/your/parquet_files
OUT_DIR=/path/to/your/output_dir
TOKENIZER=/path/to/your/tokenizer.json

# ä½¿ç”¨Dockerè¿è¡Œ
docker run --rm --init \
  -v "$DATA_DIR":/data:ro \
  -v "$OUT_DIR":/out \
  -v "$TOKENIZER":/models/tokenizer.json:ro \
  parquet2mbt:latest \
  parquet2mbt \
  --input-dir /data \
  --tokenizer /models/tokenizer.json \
  --output-prefix /out/dataset
```

## ä¸»è¦å‚æ•°æ¦‚è§ˆ

ä»…åˆ—å‡ºæœ€æ ¸å¿ƒçš„å‚æ•°ï¼Œ**æ‰€æœ‰å‚æ•°çš„è¯¦ç»†è¯´æ˜è¯·å‚è§ [ç”¨æˆ·æŒ‡å—](doc/user_guide.md)**ã€‚

- `--input-dir <PATH>`: **(å¿…éœ€)** è¾“å…¥Parquetæ–‡ä»¶æ‰€åœ¨ç›®å½•
- `--output-prefix <PATH>`: **(å¿…éœ€)** è¾“å‡ºæ–‡ä»¶å‰ç¼€
- `--tokenizer <PATH>`: **(å¿…éœ€)** Tokenizeræ–‡ä»¶è·¯å¾„
- `--batch-size <INT>`: æ‰¹å¤„ç†å¤§å°ï¼Œå½±å“å†…å­˜ä¸æ€§èƒ½
- `--target-shard-size-mb <MB>`: è¾“å‡ºåˆ†ç‰‡çš„ç›®æ ‡å¤§å°ï¼ˆMBï¼‰
- `--no-write`: æµ‹è¯•æ¨¡å¼ï¼Œä¸äº§ç”Ÿè¾“å‡ºæ–‡ä»¶
- `--help`: æ˜¾ç¤ºå…¨éƒ¨å‚æ•°

---

## æœ¬åœ°æ„å»ºï¼ˆé¢å‘å¼€å‘è€…ï¼‰

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/jk3456a/Parquet2MBT.git
cd Parquet2MBT

# 2. ç¼–è¯‘
cargo build --release

# 3. è¿è¡Œ
./target/release/parquet2mbt --help
```

---

## è¾“å‡ºæ ¼å¼

å·¥å…·ä¼šç”Ÿæˆä¸[Megatron-LM](https://github.com/NVIDIA/Megatron-LM)å®Œå…¨å…¼å®¹çš„ `.bin` å’Œ `.idx` æ–‡ä»¶ã€‚

- `<prefix>.bin`: åŒ…å«æ‰€æœ‰Token IDçš„äºŒè¿›åˆ¶æ•°æ®ã€‚
- `<prefix>.idx`: ç´¢å¼•æ–‡ä»¶ï¼Œè®°å½•æ¯ä¸ªæ–‡æ¡£åœ¨ `.bin` æ–‡ä»¶ä¸­çš„åç§»é‡ã€‚

å½“ä½¿ç”¨å¤šä¸ªå†™å…¥çº¿ç¨‹æ—¶ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆåˆ†ç‰‡æ–‡ä»¶ï¼Œå¦‚ `<prefix>.shard_00_00001.bin`ã€‚

## æ€§èƒ½ç›‘æ§

å·¥å…·ä¼šå®šæœŸè¾“å‡ºæ€§èƒ½æŒ‡æ ‡ï¼š
```
read_mb_per_sec: 245.2, convert_mb_per_sec: 89.4, records_per_sec: 12450, tokens_per_sec: 2.1M
files: 15/100, batches: 1250, records: 1.2M, tokens: 245.8M, input: 2.1GB, output: 983MB
```

## ç¯å¢ƒå˜é‡

- `RUST_LOG`: æ§åˆ¶æ—¥å¿—çº§åˆ«ï¼ˆ`debug|info|warn|error`ï¼‰
- `RAYON_NUM_THREADS`: æ§åˆ¶Rayonå†…éƒ¨å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆä»…åœ¨ä½¿ç”¨`--use-rayon-tokenize`æ—¶ç”Ÿæ•ˆï¼‰

## ç¤ºä¾‹

### å¤„ç†å•åˆ—æ–‡æœ¬
```bash
./target/release/parquet2mbt \
  --input-dir ./testdata/data \
  --tokenizer ./testdata/tokenizer.json \
  --output-prefix ./output/dataset
```

### å¤„ç†å¤šåˆ—æ–‡æœ¬å¹¶æ‹¼æ¥
```bash
./target/release/parquet2mbt \
  --input-dir /data/books \
  --concat-sep "\n\n" \
  --tokenizer /models/tokenizer.json \
  --output-prefix /output/books_dataset \
  --dtype u32
```

### é«˜æ€§èƒ½ç”Ÿäº§é…ç½®ï¼ˆæ¨èï¼‰
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆæ¨èï¼‰
./target/release/parquet2mbt \
  --input-dir /data/corpus \
  --tokenizer /models/tokenizer.json \
  --output-prefix /output/corpus 

# æˆ–æ‰‹åŠ¨æŒ‡å®šï¼ˆé«˜çº§ç”¨æˆ·ï¼‰
./target/release/parquet2mbt \
  --input-dir /data/corpus \
  --tokenizer /models/tokenizer.json \
  --output-prefix /output/corpus \
  --read-workers 4 \
  --tokenize-workers 122 \
  --write-workers 2 \
  --batch-size 8192 \
  --target-shard-size-mb 2048
```

### æ€§èƒ½æµ‹è¯•é…ç½®
```bash
# çº¯I/Oæµ‹è¯•
./target/release/parquet2mbt \
  --input-dir /data/test \
  --tokenizer /models/tokenizer.json \
  --output-prefix /tmp/test \
  --no-write \
  --workers 8

# å®Œæ•´æµæ°´çº¿æµ‹è¯•
./target/release/parquet2mbt \
  --input-dir /data/test \
  --tokenizer /models/tokenizer.json \
  --output-prefix /tmp/test \
  --no-write \
  --workers 128
```

## é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs              # ç¨‹åºå…¥å£
â”‚   â”œâ”€â”€ cli/                 # å‘½ä»¤è¡Œå‚æ•°è§£æ
â”‚   â”œâ”€â”€ config/              # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ scanner/             # æ–‡ä»¶æ‰«æ
â”‚   â”œâ”€â”€ reader/              # Parquetæ–‡ä»¶è¯»å–
â”‚   â”œâ”€â”€ preprocessor/        # æ–‡æœ¬é¢„å¤„ç†
â”‚   â”œâ”€â”€ tokenizer/           # åˆ†è¯å¤„ç†
â”‚   â”œâ”€â”€ writer/              # äºŒè¿›åˆ¶æ–‡ä»¶å†™å…¥
â”‚   â”œâ”€â”€ index/               # ç´¢å¼•æ–‡ä»¶ç”Ÿæˆ
â”‚   â””â”€â”€ pipeline/            # æµæ°´çº¿è°ƒåº¦
â”œâ”€â”€ doc/                     # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ testdata/                # æµ‹è¯•æ•°æ®
â””â”€â”€ tools/                   # è¾…åŠ©å·¥å…·è„šæœ¬
```

## ä¾èµ–é¡¹

ä¸»è¦ä¾èµ–ï¼š
- `arrow` & `parquet`: Apache Arrowç”Ÿæ€ï¼Œç”¨äºé«˜æ•ˆè¯»å–Parquetæ–‡ä»¶
- `tokenizers`: HuggingFaceåˆ†è¯å™¨Rustå®ç°
- `rayon`: æ•°æ®å¹¶è¡Œå¤„ç†
- `clap`: å‘½ä»¤è¡Œå‚æ•°è§£æ
- `tracing`: ç»“æ„åŒ–æ—¥å¿—

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§[LICENSE](LICENSE)æ–‡ä»¶ã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ç›¸å…³æ–‡æ¡£

- [äº§å“éœ€æ±‚æ–‡æ¡£ (PRD)](doc/PRD.md) - è¯¦ç»†çš„åŠŸèƒ½è§„æ ¼å’Œæ¶æ„è®¾è®¡
- [ç”¨æˆ·æŒ‡å—](doc/user_guide.md) - è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜å’Œå‚æ•°è§£é‡Š
- [é£æ´æµ‹è¯•åˆ†ææŠ¥å‘Š](doc/windtunnel_analysis_report.md) - å®Œæ•´çš„æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–åˆ†æ
- [æ€§èƒ½æŠ¥å‘Š](doc/disk_speed_report.md) - å­˜å‚¨æ€§èƒ½æµ‹è¯•å’Œå»ºè®®
